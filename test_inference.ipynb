{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c23927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.visualize import *\n",
    "from utils.FIR_filter import *\n",
    "from utils.signal_process import *\n",
    "from utils.preprocess import *\n",
    "from utils.model import *\n",
    "import utils.vision_transformer as VT\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d0dc6f",
   "metadata": {},
   "source": [
    "# Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e657751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dir, fs=10, features=['Q', 'omega', 'omega_l2', 'ANC'], start_pt=0, end_pt=-1, still_pt=300, after_still_pt=0, pool=1.0, d=0.05, window_size=128, stride=64, nperseg=128, noverlap=64, out_1=False, byCol=False):\n",
    "    total_t = 0\n",
    "    sensor_names=['imu1','imu2']\n",
    "    cols = ['q_x', 'q_y', 'q_z', 'q_w']\n",
    "    omega_axes = ['omega_u', 'omega_v', 'omega_w']\n",
    "    ang_speed_cols = ['omega']\n",
    "    anc_methods = ['LMS', 'LMS+LS', 'RLS', 'LRLS']\n",
    "\n",
    "    q_col_ls = []\n",
    "    omega_col_ls = []\n",
    "    ang_speed_col_ls = []\n",
    "    anc_col_ls = []\n",
    "\n",
    "    for imu in sensor_names:\n",
    "        for col in cols:\n",
    "            q_col_ls.append(imu + \"_\" + col)\n",
    "        for col in omega_axes:\n",
    "            omega_col_ls.append(imu + \"_\" + col)\n",
    "        for col in ang_speed_cols:\n",
    "            ang_speed_col_ls.append(imu + \"_\" + col)\n",
    "\n",
    "    for anc_method in anc_methods:\n",
    "        for col in cols:\n",
    "            anc_col_ls.append(anc_method + \"_\" + col)\n",
    "\n",
    "    spectrograms, gts = [], []\n",
    "    # iterate all files\n",
    "    for file in os.listdir(dir):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"): \n",
    "            print(os.path.join(dir, filename))\n",
    "            \n",
    "            # load data\n",
    "            data = pd.read_csv(os.path.join(dir, filename))\n",
    "            data.columns = [\n",
    "                \"Timestamp\",\n",
    "                \"imu1_q_x\",\n",
    "                \"imu1_q_y\",\n",
    "                \"imu1_q_z\",\n",
    "                \"imu1_q_w\",\n",
    "                \"imu2_q_x\",\n",
    "                \"imu2_q_y\",\n",
    "                \"imu2_q_z\",\n",
    "                \"imu2_q_w\",\n",
    "                \"Force\",\n",
    "                \"RR\",\n",
    "            ]\n",
    "\n",
    "            data = data.iloc[start_pt:end_pt]\n",
    "\n",
    "            # align delay\n",
    "            data = sp.align_delay(data, delay=10)\n",
    "            data[\"Timestamp\"] = pd.to_datetime(data[\"Timestamp\"])\n",
    "            data = data.set_index(\"Timestamp\")\n",
    "\n",
    "            # align IMU\n",
    "            q_corr = sp.Q_RANSAC(data[0:still_pt], pool=pool, d=d)\n",
    "            target, skew = 'imu1', 'imu2'\n",
    "            Q_skew = data[[skew + '_q_x', skew + '_q_y', skew + '_q_z', skew + '_q_w']].to_numpy()\n",
    "            Q_aligned = sp.align_quaternion(q_corr, Q_skew) # (sample num, 4)\n",
    "            data_aligned = data.copy()\n",
    "\n",
    "            for i, col in enumerate(cols):\n",
    "                data_aligned[[skew + '_' + col]] = Q_aligned[:, i].reshape(-1, 1)\n",
    "\n",
    "            # specify data range\n",
    "            data_sml = data_aligned.copy() # data used in sml\n",
    "            data_anc = data_aligned.copy() # data used in anc\n",
    "            data_sml = data_sml[still_pt+after_still_pt:]\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            # calculate omega features\n",
    "            if 'omega' in features:\n",
    "                for imu in sensor_names:\n",
    "                    q = data_sml[[imu + \"_\" + \"q_x\", imu + \"_\" + \"q_y\", imu + \"_\" + \"q_z\", imu + \"_\" + \"q_w\"]].values # (sample num, 4)\n",
    "                    omega = sp.q_to_omega(q)\n",
    "                    ang_speed = sp.omega_to_AngSpeed(omega)\n",
    "                    for i, omega_axis in enumerate(omega_axes):\n",
    "                        data_sml.loc[:, imu + \"_\" + omega_axis] = omega[:, i]\n",
    "                    \n",
    "                    data_sml.loc[:, imu + \"_\" + ang_speed_cols[0]] = ang_speed\n",
    "\n",
    "            # calculate ANC features\n",
    "            if 'ANC' in features:\n",
    "                anc_outputs = sp.anc_process(data_anc, NTAPS=3, LEARNING_RATE=0.001, delta=1, lam_rls=0.9995, epsilon=1e-6, lam_lrls=0.9995)\n",
    "                for anc_output in anc_outputs:\n",
    "                    method = anc_output['method']\n",
    "                    for col in cols:\n",
    "                        data_sml.loc[:, method + \"_\" + col] = anc_output[col][still_pt+after_still_pt:]\n",
    "\n",
    "                \n",
    "            # print(f'anc_outputs:{anc_outputs}')            \n",
    "\n",
    "            # Q: (sample_num, channel_num)\n",
    "            features_cols = []\n",
    "            if 'Q' in features:\n",
    "                features_cols.extend(q_col_ls)\n",
    "            if 'omega' in features:\n",
    "                features_cols.extend(omega_col_ls)\n",
    "            if 'omega_l2' in features:\n",
    "                features_cols.extend(ang_speed_col_ls)\n",
    "            if 'ANC' in features:\n",
    "                features_cols.extend(anc_col_ls)\n",
    "            Q = data_sml[features_cols].values\n",
    "            # print(f\"features_cols:{features_cols}\")\n",
    "            # print(f'Q.shape:{Q.shape}')\n",
    "            segmented_spectrograms, segmented_gt = sp.segment_data(Q, data_sml[\"Force\"], window_size=window_size, stride=stride, nperseg=nperseg, noverlap=noverlap, out_1=out_1)\n",
    "\n",
    "            # segmented_spectrograms: (num_windows, num_spectrograms, freq_bins, time_steps)\n",
    "            # min-Max normalization\n",
    "            index_sp = 0\n",
    "            if 'Q' in features:\n",
    "                segmented_spectrograms[:, index_sp:index_sp+8] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp:index_sp+8], byCol=byCol)\n",
    "                index_sp += 8\n",
    "            if 'omega' in features:\n",
    "                segmented_spectrograms[:, index_sp:index_sp+6] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp:index_sp+6], byCol=byCol)\n",
    "                index_sp += 6\n",
    "            if 'omega_l2' in features:\n",
    "                segmented_spectrograms[:, index_sp:index_sp+2] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp:index_sp+2], byCol=byCol)\n",
    "                index_sp += 2\n",
    "            if 'ANC' in features:\n",
    "                segmented_spectrograms[:, index_sp:index_sp+4] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp:index_sp+4], byCol=byCol)\n",
    "                segmented_spectrograms[:, index_sp+4:index_sp+8] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp+4:index_sp+8], byCol=byCol)\n",
    "                segmented_spectrograms[:, index_sp+8:index_sp+12] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp+8:index_sp+12], byCol=byCol)\n",
    "                segmented_spectrograms[:, index_sp+12:index_sp+16] = sp.normalize_spectrogram(segmented_spectrograms[:, index_sp+12:index_sp+16], byCol=byCol)\n",
    "                index_sp += 16\n",
    "            \n",
    "            # print(f'sepctrograms:{segmented_spectrograms.shape}')\n",
    "            # print(f'gt:{segmented_gt.shape}')\n",
    "            # exit()\n",
    "            spectrograms.append(segmented_spectrograms)\n",
    "            gts.append(segmented_gt)\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "            total_t += end_time - start_time\n",
    "    \n",
    "    spectrograms = np.concatenate(spectrograms, axis=0)\n",
    "    gts = np.concatenate(gts, axis=0)\n",
    "\n",
    "    print('----------------------------')\n",
    "    print(f'sepctrograms:{spectrograms.shape}')\n",
    "    print(f'gt:{gts.shape}')\n",
    "\n",
    "    return total_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe49286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/17P/test/run_0520_0735.csv\n",
      "best_score/total: 110/300\n",
      "./data/17P/test/run_0520_1036.csv\n",
      "best_score/total: 79/300\n",
      "./data/17P/test/run_0604_0714.csv\n",
      "best_score/total: 80/300\n",
      "./data/17P/test/run_0604_0733.csv\n",
      "best_score/total: 220/300\n",
      "./data/17P/test/run_0621_0427.csv\n",
      "best_score/total: 50/300\n",
      "./data/17P/test/run_0629_0743.csv\n",
      "best_score/total: 216/300\n",
      "./data/17P/test/run_0629_0749.csv\n",
      "best_score/total: 67/300\n",
      "./data/17P/test/sit_0520_0719.csv\n",
      "best_score/total: 176/300\n",
      "./data/17P/test/sit_0520_1022.csv\n",
      "best_score/total: 300/300\n",
      "./data/17P/test/sit_0604_0658.csv\n",
      "best_score/total: 237/300\n",
      "./data/17P/test/sit_0621_0412.csv\n",
      "best_score/total: 178/300\n",
      "./data/17P/test/sit_0629_0730.csv\n",
      "best_score/total: 74/300\n",
      "./data/17P/test/stand_0520_0724.csv\n",
      "best_score/total: 300/300\n",
      "./data/17P/test/stand_0520_1027.csv\n",
      "best_score/total: 300/300\n",
      "./data/17P/test/stand_0604_0703.csv\n",
      "best_score/total: 288/300\n",
      "./data/17P/test/stand_0621_0417.csv\n",
      "best_score/total: 300/300\n",
      "./data/17P/test/stand_0629_0734.csv\n",
      "best_score/total: 77/300\n",
      "./data/17P/test/walk_0520_0730.csv\n",
      "best_score/total: 115/300\n",
      "./data/17P/test/walk_0520_1031.csv\n",
      "best_score/total: 118/300\n",
      "./data/17P/test/walk_0604_0710.csv\n",
      "best_score/total: 231/300\n",
      "./data/17P/test/walk_0621_0422.csv\n",
      "best_score/total: 278/300\n",
      "./data/17P/test/walk_0629_0739.csv\n",
      "best_score/total: 181/300\n",
      "----------------------------\n",
      "sepctrograms:(458, 32, 65, 3)\n",
      "gt:(458, 1)\n"
     ]
    }
   ],
   "source": [
    "path_test = './data/17P/test/'\n",
    "\n",
    "# 2-D spectrogram\n",
    "window_size=256\n",
    "stride=64\n",
    "nperseg=128\n",
    "noverlap=64\n",
    "out1=True\n",
    "byCol=True\n",
    "features = ['Q', 'omega', 'omega_l2', 'ANC']\n",
    "\n",
    "spectrogram_t = prepare_data(path_test, features=features, window_size=window_size, stride=stride, nperseg=nperseg, noverlap=noverlap, out_1=out1, byCol=byCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1bf742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.358753200000137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e61dd",
   "metadata": {},
   "source": [
    "# ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95824ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_17P_32 Evaluation Results - MSE Loss: 20.6335, L1 Loss: 3.0929 1/min\n",
      "MLP_17P_32 Execution time: 9.6396 seconds\n",
      "MLP_17P_32 Total trainable parameters: 3326977\n",
      "CNN_17P_32 Evaluation Results - MSE Loss: 17.2041, L1 Loss: 3.0686 1/min\n",
      "CNN_17P_32 Execution time: 9.7578 seconds\n",
      "CNN_17P_32 Total trainable parameters: 388673\n",
      "VT_17P_32_s Evaluation Results - MSE Loss: 18.5271, L1 Loss: 3.0919 1/min\n",
      "VT_17P_32_s Execution time: 10.0681 seconds\n",
      "VT_17P_32_s Total trainable parameters: 85697\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_dir = \"dataset/\"\n",
    "dataset_name = \"17P_32\"\n",
    "pkl_test = pickle.load(open(os.path.join(dataset_dir, f'{dataset_name}_test.pkl'), 'rb'))\n",
    "input_test, gt_test = pkl_test['input'], pkl_test['gt']\n",
    "\n",
    "num_channels = input_test.shape[1]\n",
    "num_freq_bins = input_test.shape[2]\n",
    "num_time_steps = input_test.shape[3]\n",
    "\n",
    "dataset_test = IMUSpectrogramDataset(input_test, gt_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
    "\n",
    "MAE_32 = []\n",
    "\n",
    "# Load models\n",
    "# 2-D spectrogram\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models_name = ['MLP_17P_32', 'CNN_17P_32', 'VT_17P_32_s']\n",
    "models_name_show = [\"MLP\", \"CNN\", \"ViT\"]\n",
    "\n",
    "models = [MLP_out1(num_freq_bins, num_time_steps, num_channels=num_channels),\n",
    "          CNN_out1_2(num_channels=num_channels),\n",
    "          VT.ViTRegression(in_channels=num_channels, patch_size=(3, 3), emb_dim=64, mlp_dim=128, num_heads=2, num_layers=2, device=device, load=True, model_name='VT_17P_32_s'),]\n",
    "\n",
    "for i in range(len(models_name)):\n",
    "    start_time = time.perf_counter()\n",
    "    models[i].load_state_dict(torch.load(f'./models/{str(models_name[i])}.pt'))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Evaluate model in whole testing set\n",
    "    mse, mae = evaluate_model(models[i], test_loader, model_name=models_name[i], device=device)\n",
    "    MAE_32.append(mae)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    delta_t = end_time - start_time\n",
    "    total_params = sum(p.numel() for p in models[i].parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"{models_name[i]} Execution time: {(spectrogram_t+ delta_t):.4f} seconds\")\n",
    "    print(f\"{models_name[i]} Total trainable parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
